import json
import re
from typing import Dict, List
import numpy as np
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer

# ä¸‹è½½å¿…è¦çš„NLTKæ•°æ®
try:
    nltk.data.find('tokenizers/punkt')
except LookupError:
    nltk.download('punkt')

try:
    nltk.data.find('corpora/stopwords')
except LookupError:
    nltk.download('stopwords')

try:
    nltk.data.find('corpora/wordnet')
except LookupError:
    nltk.download('wordnet')

class TextSimilarityEvaluator:
    def __init__(self):
        self.lemmatizer = WordNetLemmatizer()
        self.stop_words = set(stopwords.words('english'))
        # å¯é€‰ç»„ä»¶çŠ¶æ€
        self._bert_score_available = None
        
    def preprocess_text(self, text: str) -> str:
        """é¢„å¤„ç†æ–‡æœ¬ï¼šå°å†™åŒ–ã€å»é™¤æ ‡ç‚¹ã€è¯å¹²åŒ–"""
        if not text:
            return ""
        
        # è½¬æ¢ä¸ºå°å†™
        text = text.lower()
        
        # å»é™¤ç‰¹æ®Šå­—ç¬¦å’Œæ•°å­—ï¼Œä¿ç•™å­—æ¯å’Œç©ºæ ¼
        text = re.sub(r'[^a-zA-Z\s]', ' ', text)
        
        # åˆ†è¯
        tokens = word_tokenize(text)
        
        # å»é™¤åœç”¨è¯å’Œè¯å¹²åŒ–
        processed_tokens = []
        for token in tokens:
            if token not in self.stop_words and len(token) > 2:
                lemmatized = self.lemmatizer.lemmatize(token)
                processed_tokens.append(lemmatized)
        
        return ' '.join(processed_tokens)

    def calculate_bm25_similarity(self, reference: str, candidate: str, k1: float = 1.5, b: float = 0.75) -> float:
        """è®¡ç®— BM25 ç›¸ä¼¼åº¦ï¼ˆå‚è€ƒä½œä¸ºæŸ¥è¯¢ï¼Œå€™é€‰ä½œä¸ºæ–‡æ¡£ï¼‰ï¼Œè¿”å›0-1å½’ä¸€åŒ–åˆ†æ•°"""
        if not reference or not candidate:
            return 0.0
        # è¯­æ–™ï¼šå‚è€ƒä¸å€™é€‰ä¸¤ç¯‡æ–‡æ¡£ï¼Œç”¨äºä¼°è®¡IDF
        ref_tokens = self.preprocess_text(reference).split()
        cand_tokens = self.preprocess_text(candidate).split()
        if not ref_tokens or not cand_tokens:
            return 0.0
        corpus = [ref_tokens, cand_tokens]
        N = 2
        dl = len(cand_tokens)
        avgdl = (len(ref_tokens) + len(cand_tokens)) / 2
        # è¯é¢‘ä¸æ–‡æ¡£é¢‘
        from collections import Counter
        tf_doc = Counter(cand_tokens)
        df = {}
        for token in set(ref_tokens):
            df[token] = sum(1 for doc in corpus if token in doc)
        # BM25 æ‰“åˆ†ï¼ˆå¯¹å‚è€ƒä¸­çš„å”¯ä¸€è¯æ±‚å’Œï¼‰
        score = 0.0
        unique_query_terms = set(ref_tokens)
        for term in unique_query_terms:
            n_q = df.get(term, 0)
            # åŠ 1é˜²æ­¢è´Ÿå€¼å’Œæç«¯
            idf = np.log((N - n_q + 0.5) / (n_q + 0.5) + 1.0)
            f = tf_doc.get(term, 0)
            denom = f + k1 * (1 - b + b * dl / avgdl)
            if denom == 0:
                continue
            term_score = idf * (f * (k1 + 1)) / denom
            score += term_score
        # ç®€å•å½’ä¸€åŒ–åˆ°0-1ï¼ˆå¯æŒ‰éœ€è°ƒæ•´å¸¸æ•°ï¼‰
        norm_score = score / (score + 10.0)
        return float(max(0.0, min(1.0, norm_score)))

    def _ensure_bert_score(self):
        """æ‡’æ£€æŸ¥ bert_score æ˜¯å¦å¯ç”¨ã€‚"""
        if self._bert_score_available is not None:
            return self._bert_score_available
        try:
            import bert_score  # noqa: F401
            self._bert_score_available = True
        except Exception as e:
            print(f"Warning: bert_score not available ({e}), BERTScore will be 0.0")
            self._bert_score_available = False
        return self._bert_score_available

    def calculate_bertscore_f1(self, reference: str, candidate: str, lang: str = "en") -> float:
        """è®¡ç®— BERTScore F1ï¼Œç›¸ä¼¼åº¦èŒƒå›´ [0,1]ã€‚ä¾èµ–ä¸å¯ç”¨æ—¶è¿”å› 0ã€‚"""
        if not reference or not candidate:
            return 0.0
        if not self._ensure_bert_score():
            return 0.0
        try:
            from bert_score import score as bert_score_fn
            P, R, F1 = bert_score_fn([candidate], [reference], lang=lang, verbose=False)
            f1 = float(F1.mean().item())
            return max(0.0, min(1.0, f1))
        except Exception as e:
            print(f"Warning: BERTScore failed: {e}")
            return 0.0
    
    def calculate_jaccard_similarity(self, text1: str, text2: str) -> float:
        """è®¡ç®—Jaccardç›¸ä¼¼åº¦"""
        if not text1 or not text2:
            return 0.0
        
        # é¢„å¤„ç†æ–‡æœ¬
        processed1 = set(self.preprocess_text(text1).split())
        processed2 = set(self.preprocess_text(text2).split())
        
        if not processed1 and not processed2:
            return 1.0
        if not processed1 or not processed2:
            return 0.0
        
        intersection = len(processed1.intersection(processed2))
        union = len(processed1.union(processed2))
        
        return intersection / union if union > 0 else 0.0
    
    def calculate_bleu_score(self, reference: str, candidate: str) -> float:
        """ç®€åŒ–çš„BLEUåˆ†æ•°è®¡ç®—ï¼ˆåŸºäºn-gramé‡å ï¼‰"""
        if not reference or not candidate:
            return 0.0
        
        ref_tokens = self.preprocess_text(reference).split()
        cand_tokens = self.preprocess_text(candidate).split()
        
        if not ref_tokens or not cand_tokens:
            return 0.0
        
        # è®¡ç®—1-gramå’Œ2-gramçš„ç²¾ç¡®åº¦
        def get_ngrams(tokens, n):
            return [tuple(tokens[i:i+n]) for i in range(len(tokens)-n+1)]
        
        # 1-gramç²¾ç¡®åº¦
        ref_1gram = set(get_ngrams(ref_tokens, 1))
        cand_1gram = set(get_ngrams(cand_tokens, 1))
        p1 = len(ref_1gram.intersection(cand_1gram)) / len(cand_1gram) if cand_1gram else 0
        
        # 2-gramç²¾ç¡®åº¦
        ref_2gram = set(get_ngrams(ref_tokens, 2))
        cand_2gram = set(get_ngrams(cand_tokens, 2))
        p2 = len(ref_2gram.intersection(cand_2gram)) / len(cand_2gram) if cand_2gram else 0
        
        # ç®€åŒ–çš„BLEUåˆ†æ•°
        bleu = (p1 * p2) ** 0.5
        return bleu
    
    def extract_agent_results(self, analysis_text: str) -> Dict[str, str]:
        """ä»åˆ†æç»“æœä¸­æå–å„ä¸ªagentçš„è¾“å‡º"""
        results = {}
        
        # æå–Function Agentç»“æœ
        func_match = re.search(r'ğŸ¯ FUNCTION ANALYSIS.*?----------------------------------------\n(.*?)(?=\nğŸ”¬|\nğŸ§¬|\nğŸ¯|\nğŸ“Š|\Z)', analysis_text, re.DOTALL)
        if func_match:
            results['function_agent'] = func_match.group(1).strip()
        
        # æå–Sequence Agentç»“æœ
        seq_match = re.search(r'ğŸ”¬ SEQUENCE ANALYSIS.*?----------------------------------------\n(.*?)(?=\nğŸ§¬|\nğŸ¯|\nğŸ“Š|\Z)', analysis_text, re.DOTALL)
        if seq_match:
            results['sequence_agent'] = seq_match.group(1).strip()
        
        # æå–Structure Agentç»“æœ
        struct_match = re.search(r'ğŸ§¬ STRUCTURE ANALYSIS.*?----------------------------------------\n(.*?)(?=\nğŸ¯|\nğŸ“Š|\Z)', analysis_text, re.DOTALL)
        if struct_match:
            results['structure_agent'] = struct_match.group(1).strip()
        
        # æå–Comprehensive Analysisç»“æœ
        comp_match = re.search(r'ğŸ¯ COMPREHENSIVE ANALYSIS.*?----------------------------------------\n(.*?)(?=\nğŸ“Š|\Z)', analysis_text, re.DOTALL)
        if comp_match:
            results['comprehensive_analysis'] = comp_match.group(1).strip()
        
        return results
    
    def evaluate_all_similarities(self, standard_answer: str, analysis_result: str) -> Dict[str, Dict[str, float]]:
        """è®¡ç®—æ‰€æœ‰ç›¸ä¼¼åº¦æŒ‡æ ‡"""
        # æå–å„ä¸ªagentçš„ç»“æœ
        agent_results = self.extract_agent_results(analysis_result)
        
        # å‡†å¤‡æ‰€æœ‰æ–‡æœ¬
        all_texts = [standard_answer]
        agent_names = []
        
        for agent_name, agent_text in agent_results.items():
            all_texts.append(agent_text)
            agent_names.append(agent_name)
        
        # è®¡ç®—å„ç§ç›¸ä¼¼åº¦æŒ‡æ ‡
        similarities = {}
        
        for i, agent_name in enumerate(agent_names):
            agent_text = agent_results[agent_name]
            
            # Jaccardç›¸ä¼¼åº¦
            jaccard_sim = self.calculate_jaccard_similarity(standard_answer, agent_text)
            
            # BLEUåˆ†æ•°
            bleu_score = self.calculate_bleu_score(standard_answer, agent_text)
            
            # BM25 ç›¸ä¼¼åº¦ï¼ˆå‚è€ƒä¸ºæ ‡å‡†ç­”æ¡ˆï¼Œå€™é€‰ä¸ºæ™ºèƒ½ä½“è¾“å‡ºï¼‰
            bm25_sim = self.calculate_bm25_similarity(standard_answer, agent_text)
            
            # BERTScore F1ï¼ˆè‹±è¯­ï¼‰
            bert_f1 = self.calculate_bertscore_f1(standard_answer, agent_text, lang="en")

            similarities[agent_name] = {
                'jaccard': jaccard_sim,
                'bleu': bleu_score,
                'bm25': bm25_sim,
                'bertscore_f1': bert_f1,
                'average': (jaccard_sim + bleu_score + bm25_sim)*0.4 + 0.6*bert_f1
            }
        
        return similarities

def load_standard_answer(file_path: str) -> str:
    """åŠ è½½æ ‡å‡†ç­”æ¡ˆ"""
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read().strip()
        # å¦‚æœæ˜¯JSONæ ¼å¼ï¼Œæå–æ–‡æœ¬å†…å®¹
        if content.startswith('"') and content.endswith('"'):
            content = content[1:-1]  # ç§»é™¤å¼•å·
            content = content.replace('\\n', '\n')  # è¿˜åŸæ¢è¡Œç¬¦
        return content

def load_analysis_result(file_path: str) -> str:
    """åŠ è½½åˆ†æç»“æœ"""
    with open(file_path, 'r', encoding='utf-8') as f:
        return f.read().strip()

def print_evaluation_results(similarities: Dict[str, Dict[str, float]]):
    """æ‰“å°è¯„ä¼°ç»“æœ"""
    print("=" * 80)
    print("å¤šæ™ºèƒ½ä½“ç³»ç»Ÿè¯„ä¼°ç»“æœ")
    print("=" * 80)
    
    # æŒ‰å¹³å‡ç›¸ä¼¼åº¦æ’åº
    sorted_agents = sorted(similarities.items(), key=lambda x: x[1]['average'], reverse=True)
    
    print(f"{'æ™ºèƒ½ä½“':<20} {'Jaccard':<10} {'BLEU':<10} {'BM25':<10} {'BERTScore':<10} {'å¹³å‡åˆ†':<10} {'æ’å':<5}")
    print("-" * 80)
    
    for rank, (agent_name, scores) in enumerate(sorted_agents, 1):
        print(f"{agent_name:<20} {scores['jaccard']:<10.3f} "
              f"{scores['bleu']:<10.3f} {scores['bm25']:<10.3f} {scores['bertscore_f1']:<10.3f} {scores['average']:<10.3f} {rank:<5}")
    
    print("\n" + "=" * 80)
    print("è¯¦ç»†åˆ†æ:")
    print("=" * 80)
    
    for agent_name, scores in sorted_agents:
        print(f"\n{agent_name.upper()}:")
        print(f"  Jaccardç›¸ä¼¼åº¦: {scores['jaccard']:.3f}")
        print(f"  BLEUåˆ†æ•°: {scores['bleu']:.3f}")
        print(f"  BM25ç›¸ä¼¼åº¦: {scores['bm25']:.3f}")
        print(f"  BERTScore(F1): {scores['bertscore_f1']:.3f}")
        print(f"  ç»¼åˆå¹³å‡åˆ†: {scores['average']:.3f}")
        
        

def save_evaluation_results(similarities: Dict[str, Dict[str, float]], output_file: str):
    """ä¿å­˜è¯„ä¼°ç»“æœåˆ°JSONæ–‡ä»¶"""
    results = {
        'evaluation_metrics': similarities,
        'summary': {
            'best_agent': max(similarities.items(), key=lambda x: x[1]['average'])[0],
            'worst_agent': min(similarities.items(), key=lambda x: x[1]['average'])[0],
            'overall_average': np.mean([scores['average'] for scores in similarities.values()])
        }
    }
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    print(f"\nè¯„ä¼°ç»“æœå·²ä¿å­˜åˆ°: {output_file}")

def main():
    """ä¸»å‡½æ•°"""
    # åˆå§‹åŒ–è¯„ä¼°å™¨
    evaluator = TextSimilarityEvaluator()
    
    # åŠ è½½æ•°æ®
    print("åŠ è½½æ ‡å‡†ç­”æ¡ˆå’Œåˆ†æç»“æœ...")
    standard_answer = load_standard_answer("Agents/standard_answer_A0A087X1C5.txt")
    analysis_result = load_analysis_result("Agents/CAFA/analysis_result_with_confidence_A0A087X1C5.txt")
    
    print(f"æ ‡å‡†ç­”æ¡ˆé•¿åº¦: {len(standard_answer)} å­—ç¬¦")
    print(f"åˆ†æç»“æœé•¿åº¦: {len(analysis_result)} å­—ç¬¦")
    
    # è®¡ç®—ç›¸ä¼¼åº¦
    print("\nè®¡ç®—ç›¸ä¼¼åº¦æŒ‡æ ‡...")
    similarities = evaluator.evaluate_all_similarities(standard_answer, analysis_result)
    
    # æ‰“å°ç»“æœ
    print_evaluation_results(similarities)
    
    # ä¿å­˜ç»“æœ
    save_evaluation_results(similarities, "Agents/evaluation_results_A0A087X1C5.json")
    
    return similarities

if __name__ == "__main__":
    results = main()
